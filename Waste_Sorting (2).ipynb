{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyb2N9XNDfnE"
      },
      "source": [
        "# AI Waste Sorting using transfer learning with Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1b-eEtXq6cT"
      },
      "outputs": [],
      "source": [
        "#Download and uplaod the dataset inside your drive : https://drive.google.com/drive/folders/1MdX-RLJ0AZ07qQahDevjXeF9xGKJfS5L?usp=sharing\n",
        "# Once the data ready, mont your drive inside this notebook with following code :\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJgQo7CVEVap"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIj0lGEL0IKH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hqxjt3gqzac"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import random,os,glob\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufDvEfCvE3tV"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGtPpZ1Wqzao"
      },
      "outputs": [],
      "source": [
        "data_dir  = \"/gdrive/MyDrive/dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uyr_3txkqza1"
      },
      "outputs": [],
      "source": [
        "img_list = glob.glob(os.path.join(data_dir, '*/*.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7RbQ4Hmqza4"
      },
      "outputs": [],
      "source": [
        "len(img_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8CEMi7eqza-"
      },
      "outputs": [],
      "source": [
        "classes = os.listdir(data_dir)\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdmGc6QiqzbA"
      },
      "source": [
        "## Image transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyH7AWTOqzbB"
      },
      "source": [
        "Image Resize to 300*300, normalized and converted into tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grqEF6HQqzbD"
      },
      "outputs": [],
      "source": [
        "transformations = transforms.Compose([transforms.Resize((300, 300)), transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n",
        "\n",
        "\n",
        "dataset = ImageFolder(data_dir,transform=transformations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDTe6BpfqzbL"
      },
      "source": [
        "create a helper function to see the image and its corresponding label:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-6iaxxwqzbN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_sample(img, label):\n",
        "    print(\"Label:\", dataset.classes[label], \"(Class No: \"+ str(label) + \")\")\n",
        "    plt.imshow(img.permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwWU9ljyqzbN"
      },
      "outputs": [],
      "source": [
        "img, label = dataset[2000]\n",
        "show_sample(img, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYNt0j9JqzbO"
      },
      "source": [
        "Splitting Data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-Ff5BHJqzbP"
      },
      "outputs": [],
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXeUJyziqzbR"
      },
      "source": [
        "\n",
        "\n",
        "We'll split the dataset into training, validation and test sets:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MC0-YjDqzbS"
      },
      "outputs": [],
      "source": [
        "train_ds, val_ds, test_ds = random_split(dataset, [1593, 176, 778])\n",
        "len(train_ds), len(val_ds), len(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY5WMaZcF8a4"
      },
      "source": [
        "Define batch size to 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj-G0R5VqzbU"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w3YNpD1qzbU"
      },
      "source": [
        "\n",
        "\n",
        "Now, we'll create training and validation dataloaders using DataLoader.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSwv9eknqzbV"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
        "val_dl = DataLoader(val_ds, batch_size*2, num_workers = 4, pin_memory = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCQ18HsdqzbX"
      },
      "source": [
        "\n",
        "\n",
        "This is a helper function to visualize batches:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ugq60B-qzbZ"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Iterate through the data loader\n",
        "for images, labels in train_dl:\n",
        "    # show images\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "    # print labels\n",
        "    print(' '.join('%5s' % classes[labels[j]] for j in range(images.size(0))))\n",
        "\n",
        "    # This break ensures that only one batch is displayed for simplicity.\n",
        "    # You can remove this break if you want to display images from all batches.\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXvAdZhiqzba"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow = 16).permute(1, 2, 0))\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f91PmhG6qzba"
      },
      "outputs": [],
      "source": [
        "show_batch(train_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSP-v48wqzbc"
      },
      "source": [
        "## Model 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv-I5pazGDuq"
      },
      "source": [
        "First, we define our own neural network model with pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tfxq8dKVqzbc"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch {}: train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch+1, result['train_loss'], result['val_loss'], result['val_acc']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y89skijOqzbd"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        #self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc1 = nn.Linear(16 * 72 * 72, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        #x = x.view(-1, 16 * 5 * 5)\n",
        "        x = x.view(-1, 16 * 72 * 72)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lFjc0f7GqTv"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJnU2XOUGqTz"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCNtAh8dGqT2"
      },
      "outputs": [],
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttB3PY7qGzcg"
      },
      "outputs": [],
      "source": [
        "to_device(model, device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKxhN4Hsqzbf"
      },
      "source": [
        "### Training the Model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxZIv2BRqzbf"
      },
      "source": [
        "fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_WNBoOPqzbg"
      },
      "outputs": [],
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiH_jTShqzbg"
      },
      "outputs": [],
      "source": [
        "evaluate(model, val_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzhkisXAqzbh"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imUHb_ROqzbi"
      },
      "outputs": [],
      "source": [
        "num_epochs = 8\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 5.5e-5\n",
        "\n",
        "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJaB_BdSqzbj"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "plot_accuracies(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVdj6Nmaqzbk"
      },
      "outputs": [],
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "plot_losses(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42rzu15dqzbz"
      },
      "source": [
        "## Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDNdiFCZqzb1"
      },
      "outputs": [],
      "source": [
        "class ResNet(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = models.resnet50(pretrained=True)\n",
        "        # Replace last layer\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, len(dataset.classes))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "model = ResNet()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jTdqz7k5TZZ"
      },
      "outputs": [],
      "source": [
        "to_device(model, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0z5mjRYqzb2"
      },
      "outputs": [],
      "source": [
        "evaluate(model, val_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtH3pEsyqzb3"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHLKogz7qzb3",
        "outputId": "b92c225e-5808-43a1-c01e-81f98881604d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train_loss: 1.4068, val_loss: 1.2163, val_acc: 0.8125\n",
            "Epoch 2: train_loss: 1.1704, val_loss: 1.1527, val_acc: 0.9010\n",
            "Epoch 3: train_loss: 1.1150, val_loss: 1.1395, val_acc: 0.8958\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 100\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 5.5e-5\n",
        "\n",
        "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYmjUNiwqzb4"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "plot_accuracies(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgpyFlGVqzb5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "plot_losses(history)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytGW-gMSzu_F"
      },
      "outputs": [],
      "source": [
        "torch.save({\"state_dict\": model.state_dict()}, \"/gdrive/MyDrive/TrainedModel\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWOWB6O6NE-J"
      },
      "source": [
        "### Accuracy on test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9APoeIXoqzb6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx1bUVKAcqKt"
      },
      "outputs": [],
      "source": [
        "test_dl = DataLoader(test_ds, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
        "test_dl = DeviceDataLoader(test_dl, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsFEBUAKc852"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_dl:\n",
        "        images, labels = data\n",
        "        #print(labels)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        #if (predicted == labels):\n",
        "            #class_correct[data] += 1\n",
        "\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N520F6twc65I"
      },
      "outputs": [],
      "source": [
        "class_correct = list(0. for i in range(6))\n",
        "class_total = list(0. for i in range(6))\n",
        "with torch.no_grad():\n",
        "    for data in test_dl:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "\n",
        "\n",
        "        for i in range(3):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(6):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUdtJGHiqzb5"
      },
      "source": [
        "### Visualization Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gkFFS8Lqzb8"
      },
      "outputs": [],
      "source": [
        "def predict_image(img, model):\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    prob, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "    return dataset.classes[preds[0].item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM9BAtu0qzb8"
      },
      "outputs": [],
      "source": [
        "img, label = test_ds[17]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP7TT5rOqzb9"
      },
      "outputs": [],
      "source": [
        "img, label = test_ds[23]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BITll3YSqzb9"
      },
      "outputs": [],
      "source": [
        "img, label = test_ds[1]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xdl_kTNqzcL"
      },
      "source": [
        "### Predicting External Images:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rg9KOgF9qzcM"
      },
      "outputs": [],
      "source": [
        "\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fengage.vic.gov.au%2Fapplication%2Ffiles%2F1415%2F0596%2F9236%2FDSC_0026.JPG&f=1&nofb=1\", \"plastic.jpg\")\n",
        "\n",
        "urllib.request.urlretrieve(\"https://external-content.duckduckgo.com/iu/?u=http%3A%2F%2Fi.ebayimg.com%2Fimages%2Fi%2F291536274730-0-1%2Fs-l1000.jpg&f=1&nofb=1\", \"cardboard.jpg\")\n",
        "\n",
        "urllib.request.urlretrieve(\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse4.mm.bing.net%2Fth%3Fid%3DOIP.2F0uH6BguQMctAYEJ-s-1gHaHb%26pid%3DApi&f=1\", \"cans.jpg\")\n",
        "\n",
        "urllib.request.urlretrieve(\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftinytrashcan.com%2Fwp-content%2Fuploads%2F2018%2F08%2Ftiny-trash-can-bulk-wine-bottle.jpg&f=1&nofb=1\", \"wine-trash.jpg\")\n",
        "\n",
        "urllib.request.urlretrieve(\"http://ourauckland.aucklandcouncil.govt.nz/media/7418/38-94320.jpg\", \"paper-trash.jpg\")\n",
        "\n",
        "urllib.request.urlretrieve(\"https://programmingaltanai.files.wordpress.com/2020/09/1.jpg?w=616\", \"mixed-trash.jpg\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chiUZnu0-H7Z"
      },
      "outputs": [],
      "source": [
        "loaded_model = model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPPaf05u-Kc5"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "def predict_external_image(image_name):\n",
        "    image = Image.open(Path('./' + image_name))\n",
        "\n",
        "    example_image = transformations(image)\n",
        "    plt.imshow(example_image.permute(1, 2, 0))\n",
        "    print(\"The image resembles\", predict_image(example_image, loaded_model) + \".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8ZmDlOS-Q9i"
      },
      "outputs": [],
      "source": [
        "predict_external_image('plastic.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJBN0I2R-Tm8"
      },
      "outputs": [],
      "source": [
        "predict_external_image('cans.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ies7DB2B-mfV"
      },
      "outputs": [],
      "source": [
        "predict_external_image('wine-trash.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfKsgWaXNdRH"
      },
      "outputs": [],
      "source": [
        "predict_external_image('paper-trash.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ct5P4FIN657"
      },
      "outputs": [],
      "source": [
        "predict_external_image('plastic.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kXZxmrOOjSq"
      },
      "outputs": [],
      "source": [
        "predict_external_image('mixed-trash.jpg')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}